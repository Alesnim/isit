---
description: >-
  Цель работы: ознакомится с устройством линейных моделей алгоритмов машинного
  обучения
---

# Практическая 12. Линейные модели

## Теоретические сведения

### Регрессионные модели 

В общем случае регрессия сводится к механизму суммаризации значений признаков с некоторыми весами:

$$
a(x) = w_0 + \sum_{j=1}^d w_j x_j
$$

Параметрами модели являются веса или коэффициенты $$w_j$$ . Вес $$w_0$$ также называется свободным коэффициентом или _сдвигом_ \(bias\). Заметим, что сумма в формуле является скалярным произведением вектора признаков на вектор весов. Воспользуемся этим и запишем линейную модель в более компактном виде:

$$
a(x) = w_0 + \langle w,x \rangle
$$

где $$w = (w_1, ..., w_d)$$ - вектор весов. 

Достаточно часто используется следующий приём, позволяющий упростить запись ещё сильнее. Добавим к признаковому описанию каждого объекта $$(d+1)$$ -й признак, равный единице. Вес при этом признаке как раз будет иметь смысл свободного коэффициента, и необходимость в слагаемом $$w_0$$ отпадёт:

$$
a(x) = \langle w, x \rangle
$$

Тем не менее, при такой форме следует соблюдать осторожность и помнить о наличии в выборке специального признака. Например, мы столкнёмся со сложностями, связанными с этим, когда будем говорить о регуляризации. 

За счёт простой формы линейные модели достаточно быстро и легко обучаются, и поэтому популярны при работе с большими объёмами данных. Также у них мало параметров, благодаря чему удаётся контролировать риск переобучения и использовать их для работы с зашумлёнными данными и с небольшими выборками.

### Оценка ошибки в задачах регрессии

Чтобы обучать регрессионные модели, нужно определиться, как именно измеряется качество предсказаний. Будем обозначать через y значение целевой переменной, через $$a$$ — прогноз модели. Рассмотрим несколько способов оценить отклонение $$L(y, a) $$ прогноза от истинного ответа.

Отметим, что величина среднеквадратичного отклонения плохо интерпретируется, поскольку не сохраняет единицы измерения — так, если мы предсказываем цену в рублях, то MSE будет измеряться в квадратах рублей. Чтобы избежать этого, используют корень из среднеквадратичной ошибки \(root mean squared error, RMSE\):

$$
RMSE(a,X) = \sqrt{\frac{1}{l} \sum_{i=1}^l (a(x_i) - y_i)^2}
$$

Среднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения, но не позволяет сделать выводы том, насколько хорошо данная модель решает задачу. 

Например, MSE = 10 является очень плохим показателем, если целевая переменная принимает значения от 0 до 1, и очень хорошим, если целевая переменная лежит в интервале \(10000, 100000\). В таких ситуациях вместо среднеквадратичной ошибки полезно использовать _коэффициент детерминации_ \(или коэффициент $$R^2$$\):

$$
R^2(a,X) = 1 - \frac{\sum_{i =1}^l (a(x_i) - y_i)^2}{\sum_{i=1}^l (y_i - \bar{y})^2}
$$

где  $$\bar{y} = \frac{1}{l}\sum_{i=1}^l y_i$$— среднее значение целевой переменной. Коэффициент детерминации измеряет долю дисперсии, объяснённую моделью, в общей дисперсии целевой переменной. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием.

Заменим квадрат отклонения на модуль:

$$
L(y, a) = | a - y|
$$

Соответствующий функционал называется средним _абсолютным отклонением_ \(mean absolute error, MAE\):

$$
MAE(a,X) = \frac{1}{l} \sum_{i=1}^l |a(x_i) - y_i|
$$

Модуль отклонения не является дифференцируемым, но при этом менее чувствителен к выбросам. Квадрат отклонения, по сути, делает особый акцент на объектах с сильной ошибкой, и метод обучения будет в первую очередь стараться уменьшить отклонения на таких объектах. Если же эти объекты являются выбросами \(то есть значение целевой переменной на них либо ошибочно, либо относится к другому распределению и должно быть проигнорировано\), то такая расстановка акцентов приведёт к плохому качеству модели. Модуль отклонения в этом смысле гораздо более терпим к сильным ошибкам.

Приведём ещё одно объяснение того, почему модуль отклонения устойчив к выбросам, на простом примере. Допустим, все $$l$$ объектов выборки имеют одинаковые признаковые описания, но разные значения целевой переменной $$y_1, ..., y_l$$. В этом случае модель должна на всех этих объектах выдать один и тот же ответ. Если мы выбрали MSE в качестве функционала ошибки, то получаем следующую задачу:

$$
\frac{1}{l}\sum_{i=1}^l (a - y_i)^2 \to \min \limits_{a}
$$

Если один из ответов на порядки отличается от всех остальных \(то есть является выбросом\), то среднее будет существенно отклоняться в его сторону.

Перейдём теперь к логарифмам ответов и прогнозов:

$$
L(y,a) = (log(a+1) - log(y+1))^2
$$

Соответствующий функционал называется среднеквадратичной _логарифмической ошибкой_ \(mean squared logarithmic error, MSLE\). Данная метрика подходит для задач с неотрицательной целевой переменной. За счёт логарифмирования ответов и прогнозов мы скорее штрафуем за отклонения в порядке величин, чем за отклонения в их значениях. Также следует помнить, что логарифм не является симметричной функцией, и поэтому данная функция потерь штрафует заниженные прогнозы сильнее, чем завышенные.

В задачах прогнозирования обычно измеряется относительная ошибка:

$$
L(y,a) = \left| \frac{y-a}{y} \right|
$$

Соответствующий функционал называется средней _абсолютной процентной ошибкой_ \(mean absolute percentage error, MAPE\). Данный функционал часто используется в задачах прогнозирования. Также используется его симметричная модификация \(symmetric mean absolute percentage error, SMAPE\):

$$
L(y,a) = \frac{|y-a|}{(|y| + |a| )/2}
$$

### Обучение линейной регрессии

Чаще всего линейная регрессия обучается с использованием среднеквадратичной ошибки. В этом случае получаем задачу оптимизации \(считаем, что среди признаков есть константный, и поэтому свободный коэффициент не нужен\):

$$
\frac{1}{l}\sum_{i=1}^l (\langle w_i, x_i \rangle  - y_i)^2 \to \min\limits_w
$$

Эту задачу можно переписать в матричном виде. Если $$X$$ — матрица «объекты-признаки», $$y$$ — вектор ответов, $$w$$ — вектор параметров, то приходим к виду

$$
\frac{1}{l}\|X_w - y \|^2 \to \min\limits_w
$$

где используется обычная $$L_2$$ -норма. Если продифференцировать данный функционал по вектору $$w$$, приравнять к нулю и решить уравнение, то получим явную формулу для решения:

$$
w = (X^T X)^{-1} X^T y
$$

Безусловно, наличие явной формулы для оптимального вектора весов — это большое преимущество линейной регрессии с квадратичным функционалом. Но данная формула не всегда применима по ряду причин: 

* Обращение матрицы — сложная операция с кубической сложностью от количества признаков. Если в выборке тысячи признаков, то вычисления могут стать слишком трудоёмкими. Решить эту проблему можно путём использования численных методов оптимизации. 
* Матрица $$X^T X$$ может быть вырожденной или плохо обусловленной. В этом случае обращение либо невозможно, либо может привести к неустойчивым результатам. Проблема решается с помощью регуляризации, речь о которой пойдёт ниже.

Следует понимать, что аналитические формулы для решения довольно редки в машинном обучении. Если мы заменим MSE на другой функционал, то найти такую формулу, скорее всего, не получится. Желательно разработать общий подход, в рамках которого можно обучать модель для широкого класса функционалов. Такой подход действительно есть для дифференцируемых функций — обсудим его подробнее.

### Градиентный спуск

Градиентом функции $$f: \mathbb{R}^d  \to \mathbb{R}$$называется вектор его частных производных:

$$
\nabla f(x_1, ..., x_d) = \left(  \frac{\partial f}{\partial 
 x_j } \right)^d_{j=1}
$$

Градиент является направлением наискорейшего роста функции, а антиградиент \(т.е. $$- \nabla f$$ \) — направлением наискорейшего убывания. Это ключевое свойство градиента, обосновывающее его использование в методах оптимизации.

Докажем данное утверждение. Пусть $$v \in \mathbb{R}^d$$ — произвольный вектор, лежащий на единичной сфере: $$\| v \| = 1$$. Пусть $$x_0 \in \mathbb{R}^d$$ — фиксированная точка пространства. Скорость роста функции в точке $$x_0$$ вдоль вектора$$v$$характеризуется производной по направлению$$\frac{\partial f}{\partial v}$$:

$$
\frac{\partial f}{\partial v} = \frac{d}{dt}f(x_{0,1} + tv_1, ..., x_{0,d} + tv_d) |_{t=0}
$$

Распишем скалярное произведение:

$$
\langle \nabla f, v \rangle = \| \nabla f \| \|v\| cos \varphi = \| \nabla f \| cos \varphi
$$

где $$\varphi$$ — угол между градиентом и вектором $$v$$. Таким образом, производная по направлению будет максимальной, если угол между градиентом и направлением равен нулю, и минимальной, если угол равен 180 градусам. Иными словами, **производная по направлению максимальна вдоль градиента и минимальна вдоль антиградиента**.

Основное свойство антиградиента — он указывает в сторону наискорейшего убывания функции в данной точке. Соответственно, будет логично стартовать из некоторой точки, сдвинуться в сторону антиградиента, пересчитать антиградиент и снова сдвинуться в его сторону и т.д. Запишем это более формально. Пусть $$w^{(0)}$$ — начальный набор параметров \(например, нулевой или сгенерированный из некоторого случайного распределения\). Тогда градиентный спуск состоит в повторении следующих шагов до сходимости:

$$
w^{(k)} = w^{k-1} - \eta_k \nabla Q (w^{k-1})
$$

Здесь под$$Q(w)$$понимается значение функционала ошибки для набора параметров$$w$$.

Через $$\eta_k$$ обозначается длина шага, которая нужна для контроля скорости движения. Можно делать её константной: $$\eta_k = c$$ . При этом если длина шага слишком большая, то есть риск постоянно «перепрыгивать» через точку минимума, а если шаг слишком маленький, то движение к минимуму может занять слишком много итераций. 

Иногда длину шага монотонно уменьшают по мере движения — например, по простой формуле:

$$
\eta_k = \frac{1}{k}
$$

Останавливать итерационный процесс можно, например, при близости градиента к нулю или при слишком малом изменении вектора весов на последней итерации. Если функционал $$Q(w)$$ выпуклый, гладкий и имеет минимум $$w^*$$ , то имеет место следующая оценка сходимости:

$$
Q(w^{(k)}) - Q(w^*) = Q(1/k)
$$

### Оценивание градиента

Как правило, в задачах машинного обучения функционал $$Q(w)$$ представим в виде суммы $$l$$ функций:

$$
Q(w) = \sum_{i=1}^l q_i(w)
$$

Проблема метода градиентного спуска состоит в том, что на каждом шаге необходимо вычислять градиент всей суммы \(будем его называть полным градиентом\):

$$
\nabla_w Q(w) = \sum_{i=1}^l \nabla_w q_i(w)
$$

Это может быть очень трудоёмко при больших размерах выборки. В то же время точное вычисление градиента может быть не так уж необходимо — как правило, мы делаем не очень большие шаги в сторону антиградиента, и наличие в нём неточностей не должно сильно сказаться на общей траектории. Опишем несколько способов оценивания полного градиента.

Оценить градиент суммы функций можно градиентом одного случайно взятого слагаемого. В этом случае мы получим метод _стохастического градиентного спуска_ \(stochastic gradient descent, SGD\):

$$
w^{(k)} = w^{(k-1)} - \eta_k \nabla q_{i_k} (w^{(k-1)})
$$

где $$i_k$$ — случайно выбранный номер слагаемого из функционала

Существует множество других способов получения оценки градиента. Например, это можно делать без вычисления каких-либо градиентов вообще — достаточно взять случайный вектор $$u$$ на единичной сфере и домножить его на значение функции в данном направлении:

$$
\nabla_wQ(w) = Q(w + \delta u) u
$$



