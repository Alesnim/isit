---
description: >-
  Цель работы: ознакомится с устройством линейных моделей алгоритмов машинного
  обучения
---

# Практическая 12. Линейные модели

## Теоретические сведения

### Регрессионные модели 

В общем случае регрессия сводится к механизму суммаризации значений признаков с некоторыми весами:

$$
a(x) = w_0 + \sum_{j=1}^d w_j x_j
$$

Параметрами модели являются веса или коэффициенты $$w_j$$ . Вес $$w_0$$ также называется свободным коэффициентом или _сдвигом_ \(bias\). Заметим, что сумма в формуле является скалярным произведением вектора признаков на вектор весов. Воспользуемся этим и запишем линейную модель в более компактном виде:

$$
a(x) = w_0 + \langle w,x \rangle
$$

где $$w = (w_1, ..., w_d)$$ - вектор весов. 

Достаточно часто используется следующий приём, позволяющий упростить запись ещё сильнее. Добавим к признаковому описанию каждого объекта $$(d+1)$$ -й признак, равный единице. Вес при этом признаке как раз будет иметь смысл свободного коэффициента, и необходимость в слагаемом $$w_0$$ отпадёт:

$$
a(x) = \langle w, x \rangle
$$

Тем не менее, при такой форме следует соблюдать осторожность и помнить о наличии в выборке специального признака. Например, мы столкнёмся со сложностями, связанными с этим, когда будем говорить о регуляризации. 

За счёт простой формы линейные модели достаточно быстро и легко обучаются, и поэтому популярны при работе с большими объёмами данных. Также у них мало параметров, благодаря чему удаётся контролировать риск переобучения и использовать их для работы с зашумлёнными данными и с небольшими выборками.

### Оценка ошибки в задачах регрессии

Чтобы обучать регрессионные модели, нужно определиться, как именно измеряется качество предсказаний. Будем обозначать через y значение целевой переменной, через $$a$$ — прогноз модели. Рассмотрим несколько способов оценить отклонение $$L(y, a) $$ прогноза от истинного ответа.

Отметим, что величина среднеквадратичного отклонения плохо интерпретируется, поскольку не сохраняет единицы измерения — так, если мы предсказываем цену в рублях, то MSE будет измеряться в квадратах рублей. Чтобы избежать этого, используют корень из среднеквадратичной ошибки \(root mean squared error, RMSE\):

$$
RMSE(a,X) = \sqrt{\frac{1}{l} \sum_{i=1}^l (a(x_i) - y_i)^2}
$$

Среднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения, но не позволяет сделать выводы том, насколько хорошо данная модель решает задачу. 

Например, MSE = 10 является очень плохим показателем, если целевая переменная принимает значения от 0 до 1, и очень хорошим, если целевая переменная лежит в интервале \(10000, 100000\). В таких ситуациях вместо среднеквадратичной ошибки полезно использовать _коэффициент детерминации_ \(или коэффициент $$R^2$$\):

$$
R^2(a,X) = 1 - \frac{\sum_{i =1}^l (a(x_i) - y_i)^2}{\sum_{i=1}^l (y_i - \bar{y})^2}
$$

где  $$\bar{y} = \frac{1}{l}\sum_{i=1}^l y_i$$— среднее значение целевой переменной. Коэффициент детерминации измеряет долю дисперсии, объяснённую моделью, в общей дисперсии целевой переменной. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием.

Заменим квадрат отклонения на модуль:

$$
L(y, a) = | a - y|
$$

Соответствующий функционал называется средним _абсолютным отклонением_ \(mean absolute error, MAE\):

$$
MAE(a,X) = \frac{1}{l} \sum_{i=1}^l |a(x_i) - y_i|
$$

Модуль отклонения не является дифференцируемым, но при этом менее чувствителен к выбросам. Квадрат отклонения, по сути, делает особый акцент на объектах с сильной ошибкой, и метод обучения будет в первую очередь стараться уменьшить отклонения на таких объектах. Если же эти объекты являются выбросами \(то есть значение целевой переменной на них либо ошибочно, либо относится к другому распределению и должно быть проигнорировано\), то такая расстановка акцентов приведёт к плохому качеству модели. Модуль отклонения в этом смысле гораздо более терпим к сильным ошибкам.

Приведём ещё одно объяснение того, почему модуль отклонения устойчив к выбросам, на простом примере. Допустим, все $$l$$ объектов выборки имеют одинаковые признаковые описания, но разные значения целевой переменной $$y_1, ..., y_l$$. В этом случае модель должна на всех этих объектах выдать один и тот же ответ. Если мы выбрали MSE в качестве функционала ошибки, то получаем следующую задачу:

$$
\frac{1}{l}\sum_{i=1}^l (a - y_i)^2 \to \min \limits_{a}
$$

Если один из ответов на порядки отличается от всех остальных \(то есть является выбросом\), то среднее будет существенно отклоняться в его сторону.

Перейдём теперь к логарифмам ответов и прогнозов:

$$
L(y,a) = (log(a+1) - log(y+1))^2
$$

Соответствующий функционал называется среднеквадратичной _логарифмической ошибкой_ \(mean squared logarithmic error, MSLE\). Данная метрика подходит для задач с неотрицательной целевой переменной. За счёт логарифмирования ответов и прогнозов мы скорее штрафуем за отклонения в порядке величин, чем за отклонения в их значениях. Также следует помнить, что логарифм не является симметричной функцией, и поэтому данная функция потерь штрафует заниженные прогнозы сильнее, чем завышенные.

В задачах прогнозирования обычно измеряется относительная ошибка:

$$
L(y,a) = \left| \frac{y-a}{y} \right|
$$

Соответствующий функционал называется средней _абсолютной процентной ошибкой_ \(mean absolute percentage error, MAPE\). Данный функционал часто используется в задачах прогнозирования. Также используется его симметричная модификация \(symmetric mean absolute percentage error, SMAPE\):

$$
L(y,a) = \frac{|y-a|}{(|y| + |a| )/2}
$$

### Обучение линейной регрессии

Чаще всего линейная регрессия обучается с использованием среднеквадратичной ошибки. В этом случае получаем задачу оптимизации \(считаем, что среди признаков есть константный, и поэтому свободный коэффициент не нужен\):

$$
\frac{1}{l}\sum_{i=1}^l (\langle w_i, x_i \rangle  - y_i)^2 \to \min\limits_w
$$

Эту задачу можно переписать в матричном виде. Если $$X$$ — матрица «объекты-признаки», $$y$$ — вектор ответов, $$w$$ — вектор параметров, то приходим к виду

$$
\frac{1}{l}\|X_w - y \|^2 \to \min\limits_w
$$

где используется обычная $$L_2$$ -норма. Если продифференцировать данный функционал по вектору $$w$$, приравнять к нулю и решить уравнение, то получим явную формулу для решения:

$$
w = (X^T X)^{-1} X^T y
$$

Безусловно, наличие явной формулы для оптимального вектора весов — это большое преимущество линейной регрессии с квадратичным функционалом. Но данная формула не всегда применима по ряду причин: 

* Обращение матрицы — сложная операция с кубической сложностью от количества признаков. Если в выборке тысячи признаков, то вычисления могут стать слишком трудоёмкими. Решить эту проблему можно путём использования численных методов оптимизации. 
* Матрица $$X^T X$$ может быть вырожденной или плохо обусловленной. В этом случае обращение либо невозможно, либо может привести к неустойчивым результатам. Проблема решается с помощью регуляризации, речь о которой пойдёт ниже.

Следует понимать, что аналитические формулы для решения довольно редки в машинном обучении. Если мы заменим MSE на другой функционал, то найти такую формулу, скорее всего, не получится. Желательно разработать общий подход, в рамках которого можно обучать модель для широкого класса функционалов. Такой подход действительно есть для дифференцируемых функций — обсудим его подробнее.

### Градиентный спуск

Градиентом функции $$f: \mathbb{R}^d  \to \mathbb{R}$$называется вектор его частных производных:

$$
\nabla f(x_1, ..., x_d) = \left(  \frac{\partial f}{\partial 
 x_j } \right)^d_{j=1}
$$

Градиент является направлением наискорейшего роста функции, а антиградиент \(т.е. $$- \nabla f$$ \) — направлением наискорейшего убывания. Это ключевое свойство градиента, обосновывающее его использование в методах оптимизации.

Докажем данное утверждение. Пусть $$v \in \mathbb{R}^d$$ — произвольный вектор, лежащий на единичной сфере: $$\| v \| = 1$$. Пусть $$x_0 \in \mathbb{R}^d$$ — фиксированная точка пространства. Скорость роста функции в точке $$x_0$$ вдоль вектора$$v$$характеризуется производной по направлению$$\frac{\partial f}{\partial v}$$:

$$
\frac{\partial f}{\partial v} = \frac{d}{dt}f(x_{0,1} + tv_1, ..., x_{0,d} + tv_d) |_{t=0}
$$

Распишем скалярное произведение:

$$
\langle \nabla f, v \rangle = \| \nabla f \| \|v\| cos \varphi = \| \nabla f \| cos \varphi
$$

где $$\varphi$$ — угол между градиентом и вектором $$v$$. Таким образом, производная по направлению будет максимальной, если угол между градиентом и направлением равен нулю, и минимальной, если угол равен 180 градусам. Иными словами, **производная по направлению максимальна вдоль градиента и минимальна вдоль антиградиента**.

Основное свойство антиградиента — он указывает в сторону наискорейшего убывания функции в данной точке. Соответственно, будет логично стартовать из некоторой точки, сдвинуться в сторону антиградиента, пересчитать антиградиент и снова сдвинуться в его сторону и т.д. Запишем это более формально. Пусть $$w^{(0)}$$ — начальный набор параметров \(например, нулевой или сгенерированный из некоторого случайного распределения\). Тогда градиентный спуск состоит в повторении следующих шагов до сходимости:

$$
w^{(k)} = w^{k-1} - \eta_k \nabla Q (w^{k-1})
$$

Здесь под$$Q(w)$$понимается значение функционала ошибки для набора параметров$$w$$.

Через $$\eta_k$$ обозначается длина шага, которая нужна для контроля скорости движения. Можно делать её константной: $$\eta_k = c$$ . При этом если длина шага слишком большая, то есть риск постоянно «перепрыгивать» через точку минимума, а если шаг слишком маленький, то движение к минимуму может занять слишком много итераций. 

Иногда длину шага монотонно уменьшают по мере движения — например, по простой формуле:

$$
\eta_k = \frac{1}{k}
$$

Останавливать итерационный процесс можно, например, при близости градиента к нулю или при слишком малом изменении вектора весов на последней итерации. Если функционал $$Q(w)$$ выпуклый, гладкий и имеет минимум $$w^*$$ , то имеет место следующая оценка сходимости:

$$
Q(w^{(k)}) - Q(w^*) = Q(1/k)
$$

### Оценивание градиента

Как правило, в задачах машинного обучения функционал $$Q(w)$$ представим в виде суммы $$l$$ функций:

$$
Q(w) = \sum_{i=1}^l q_i(w)
$$

Проблема метода градиентного спуска состоит в том, что на каждом шаге необходимо вычислять градиент всей суммы \(будем его называть полным градиентом\):

$$
\nabla_w Q(w) = \sum_{i=1}^l \nabla_w q_i(w)
$$

Это может быть очень трудоёмко при больших размерах выборки. В то же время точное вычисление градиента может быть не так уж необходимо — как правило, мы делаем не очень большие шаги в сторону антиградиента, и наличие в нём неточностей не должно сильно сказаться на общей траектории. Опишем несколько способов оценивания полного градиента.

Оценить градиент суммы функций можно градиентом одного случайно взятого слагаемого. В этом случае мы получим метод _стохастического градиентного спуска_ \(stochastic gradient descent, SGD\):

$$
w^{(k)} = w^{(k-1)} - \eta_k \nabla q_{i_k} (w^{(k-1)})
$$

где $$i_k$$ — случайно выбранный номер слагаемого из функционала

Существует множество других способов получения оценки градиента. Например, это можно делать без вычисления каких-либо градиентов вообще — достаточно взять случайный вектор $$u$$ на единичной сфере и домножить его на значение функции в данном направлении:

$$
\nabla_wQ(w) = Q(w + \delta u) u
$$

### Линейная регрессия в Scipy

Для примера рассмотрим некоторую зависимость $$x$$ и $$y$$.

| x | 1 | 2 | 3 | 4 | 5 | 6 | 12 | 17 | 20 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| y | 4 | 3 | 3 | 8 | 4 | 5 | 8 | 12 | 17 |

Создадим переменные содержащие данные:

```python
import numpy as np
x = [1,2, 3, 4, 5, 6, 12, 17, 20]
y = [4, 3, 3, 8, 4, 5, 8, 12, 17]
x = np.array(x)
y = np.array(y)
```

Выведем график точек, для просмотра распределения:

```python
import matplotlib.pyplot as plt
plt.scatter(x, y)
```

![](../.gitbook/assets/image%20%2874%29.png)

Попробуем найти приближенную линейную зависимость и вывести график. Для этого необходимо выяснить угол наклона прямой $$b$$ :

```python
b = x / y
plt.scatter(x, y)
c = x + b
plt.plot(x, c, 'r--')
```

![](../.gitbook/assets/image%20%2877%29.png)

Теперь воспользуемся  моделью линейной регрессии из библиотеки _Sklearn_  для восстановления зависимости:

```python
x = x.reshape(-1, 1)
y = y.reshape(-1, 1)

from sklearn.linear_model import LinearRegression
slr = LinearRegression()
slr.fit(x, y)
y_pred = slr.predict(x)
```

После поиска модель содержит коэфициенты линейной зависимости $$a \cdot x +b $$ . Построим график прямой с найденными коэфициентами:

```python
print('Коэфициент наклона: {:.2f}'.format(float(slr.coef_[0])))
print('Сдвиг: {:.2f}'.format(float(slr.intercept_)))
```

```python
plt.scatter(x, y)
plt.plot(x, c, 'g--')
plt.plot(x, slr.predict(x), 'r')
```

Полученный график изображен на рисунке 1.

![&#x420;&#x438;&#x441;&#x443;&#x43D;&#x43E;&#x43A; 1 - &#x413;&#x440;&#x430;&#x444;&#x438;&#x43A;&#x438; &#x440;&#x435;&#x433;&#x440;&#x435;&#x441;&#x441;&#x438;&#x438; &#x43D;&#x430; &#x432;&#x44B;&#x431;&#x43E;&#x440;&#x43A;&#x435;](../.gitbook/assets/image%20%2876%29.png)

## Регуляризация линейных моделей

Регуляризация — это метод для уменьшения степени переобучения модели, а значит, прежде чем мы разберемся, что такое регуляризация, нужно понять суть переобучения \(overfitting\).

![](../.gitbook/assets/image%20%2878%29.png)

Переобучение дает неплавные кривые прогнозирования, т. е. «нерегулярные». Такие плохие сложные кривые прогнозирования обычно характеризуются весовыми значениями, которые имеют очень большие или очень малые величины. Поэтому один из способов уменьшить степень переобучения состоит в том, чтобы не допускать очень малых или больших весовых значений для модели. В этом и заключается суть регуляризации.

Линейная регрессия с большим числом предикторов – комплексная модель и характеризуется:

* Достаточно высоким смещением
* Высокой дисперсией

Чем больше предикторов, тем больше риск переобучения модели. Переобучение также связано с размером коэфициентов.

Переобучение – ситуация, в которой обучающая ошибка продолжает снижаться с повышением сложности модели, а тестовая ошибка растет.

Как с этим бороться?

* Отбор наилучших предикторов
* Снижение размерности предикторов
* Регуляризация

Регуляризация — это способ уменьшить сложность модели чтобы предотвратить переобучение или исправить некорректно поставленную задачу. Обычно это достигается добавлением некоторой априорной информации к условию задачи.

В данном случае суть регуляризации состит в том, что мы создаём модель со всеми предикторами, а потом искуственно уменьшаем размер коэффициентов, прибавляя некоторую величину к ошибке.

Ошибка — это то, что минимизируется обучением с помощью одного из примерно десятка численных методов вроде градиентного спуска \(gradient descent\), итерационного алгоритма Ньютона-Рафсона \(iterative Newton-Raphson\), L-BFGS, обратного распространения ошибок \(back-propagation\) и оптимизации роя \(swarm optimization\).

Чтобы величины весовых значений модели не становились большими, процесс регуляризации штрафует весовые значения добавляя их в вычисление ошибки. Если весовые значения включаются в общую ошибку, которая минимизируется, тогда меньшие весовые значения будут давать меньшие значения ошибки. L1-регуляризация штрафует весовые значения добавлением суммы их абсолютных значений к ошибке.

L2-регуляризация выполняет аналогичную операцию добавлением суммы их квадратов к ошибке.

#### Ридж-регрессия

Ридж-регрессия или гребневая регрессия \(ridge regression\) - это один из методов понижения размерности. Часто его применяют для борьбы с переизбыточностью данных, когда независимые переменные коррелируют друг с другом \(т.е. имеет место мультиколлинеарность\).

* Ридж регрессия снижает размер коэффициентов, а лассо сокращает многие до 0
* Это позволяет снизить размерность \(ридж\) и выбрать важные предикторы \(лассо\)
* Работает, когда p &gt; n, где p — число предикторов
* Работает, когда много коллинеарных предикторов
* Обязательно надо делать шкалирование и центрирование, иначе предикторы с высоким стандартным отклонением будут сильно штравоваться.

### Регуляризация в Sklearn

```python
from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
sc_y = StandardScaler()
X_std = sc_x.fit_transform(x)
y_std = sc_y.fit_transform(y.reshape(-1, 1)).flatten()
```

Теперь дисперсия и отклонение в выборке данных снижено с сохранением корреляционных параметров. 

Используем лассо-регрессию: 

```python
from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.1)
lasso.fit(X_std, y_std)
```

Сравним с результатом стандартной модели корреляции: 

```python
plt.scatter(x, y)
plt.plot(x, lasso.predict(x), 'g', label='Lasso regression')
plt.plot(x, slr.predict(x), 'r', label='Standart algo')
```

![](../.gitbook/assets/image%20%2875%29.png)

Используем ридж-регрессию:

```python
from sklearn.linear_model import Ridge

ridge = Ridge(alpha=0.1)
ridge.fit(X_train_scaled, y_train_scaled)
```

Сравним с результатами предыдущих моделей:

![](../.gitbook/assets/image%20%2879%29.png)



## Ход работы 

### Задание 1. "Ручная" регрессия

Посчитайте линейную регрессионную модель самостоятельно для случайной выборки данных, используя описанные ранее формулу и библиотеку `numpy`. Проверьте, совпадают ли коэффициенты с результатами `sklearn`.

Подсказки:

* «Склеить» два столбца можно при помощи `np.hstack`.
* Для получения обратной матрицы можно использовать `np.linalg.inv`.
* Матричное умножение осуществляет `np.dot`.

### Задание 1. Линейная регрессия в Sklearn

В Основах химии Д. И. Менделеева приводятся данные о растворимости азотнокислого натрия $$\text{Na} \text{NO}_3$$ в зависимости от температуры воды Число условных частей $$\text{Na} \text{NO}_3$$ в 100 растворяющихся в частях воды при соответствующих температурах представлено в таблице. Требуется определить растворимость азотнокислого натрия при температуре 32 градуса в случае линейной зависимости и найти коэффициент и индекс корреляции. Рассчитайте коэфициент детерминации для полученной корреляции. 

| Температура воды | Растворимость |
| :--- | :--- |
| 0 | 66.7 |
| 4 | 71.0 |
| 10 | 76.3 |
| 15 | 80.6 |
| 21 | 85.7 |
| 29 | 92.9 |
| 36 | 99.4 |
| 51 | 113.6 |
| 68 | 125.1 |

### Задание 2. Линейная регрессия в Scilab

Имеются данные средней выработки на одного рабочего y \(тыс. руб.\) и товарооборота x \(тыс. руб.\) в 20 магазинах за квартал. Требуется найти коэффициент и индекс корреляции.

| Выработка рабочего | Товарооборот |
| :--- | :--- |
| 10  | 3,8 |
| 14 |  4,8 |
|  21 |  5,9 |
|  23 |  6,1 |
|  27 |  6,2 |
|  32 |  6,3 |
|  39  |  6,6  |
| 45 | 7,4  |
| 55 | 8,5  |
| 61 | 9,7  |
| 62 | 10,5  |
| 68 | 12,4 |

### Задание 3. Линейная регрессия в Scilab

Компанию по прокату автомобилей интересует зависимость между пробегом автомобилей X и стоимостью ежемесячного технического обслуживания Y . Для выяснения характера этой связи было отобрано 15 автомобилей. Постройте график исходных данных и определите по нему характер зависимости. Постройте уравнение регрессии и дайте интерпретацию полученных результатов.

| Пробег автомобиля | Стоимость ТО |
| :--- | :--- |
| 6 | 13 |
| 7 | 16 |
| 8 | 15 |
| 9 | 20 |
| 10 | 19 |
| 11 | 21 |
| 12 | 26 |
| 13 | 24 |
| 14 | 30 |
| 15 | 32 |
| 16 | 30 |
| 17 | 35 |
| 18 | 34 |
| 19 | 40 |
| 20 | 39 |

## Контрольные вопросы

1. Какой функционал контроля ошибок лучше использовать при прогнозировании
2. Что такое линейная регрессия
3. Что такое градиент и антиградиент и чем они отличаются
4. Объясните работу метода градиентного спуска

### **Критерии оценки практического занятия**

Оценивается знание материала, способность к его обобщению, критическому осмыслению, систематизации. 

* 3 балла: студент полностью выполнил задания.
* 2 балла: в усвоении учебного материала допущены небольшие пробелы.
* 1 балл: неполно или непоследовательно реализовано задание.
* 0 баллов: не раскрыто основное содержание учебного материала.

**Максимальный балл: 3 балла**



