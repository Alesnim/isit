---
description: 'Цель работы: ознакомится с механизмом классификации'
---

# Практическая 13. Линейные модели классификации

## Теоретические сведения

Мы начнём с задачи бинарной классификации, а многоклассовый случай обсудим позже. Пусть $$\mathbb{X} = \mathbb{R}^d$$— пространство объектов, $$Y = \{ -1, 1\}$$— множество допустимых ответов, $$X = \{ x_i, y_i \}^l_{i=1}$$— обучающая выборка. Иногда мы будем класс «+1» называть положительным, а класс «−1» — отрицательным.

Линейная модель классификации определяется следующим образом:

$$
a(x) = sign(\langle w,x \rangle + w_0) = sign \left(
\sum_{j=1}^d w_j x_j + w_0
 \right)
$$

где $$w \in \mathbb{R}^d$$— вектор весов,  $$w_0 \in \mathbb{R}$$ — сдвиг \(bias\).

Если не сказано иначе, мы будем считать, что среди признаков есть константа, $$x_d+1 = 1$$ . В этом случае нет необходимости вводить сдвиг w0, и линейный классификатор можно задавать как:

$$
a(x) = sign \langle w, x \rangle.
$$

Геометрически линейный классификатор соответствует гиперплоскости с вектором нормали $$w$$ . Величина скалярного произведения $$\langle w, x \rangle$$ пропорциональна расстоянию от гиперплоскости до точки $$x$$ , а его знак показывает, с какой стороны от гиперплоскости находится данная точка.

Таким образом, линейный классификатор разделяет пространство на две части с помощью гиперплоскости, и при этом одно полупространство относит к положительному классу, а другое — к отрицательному.

### Обучение линейных классификаторов

В задаче регрессии имеется континуум возможных ответов, и при таких условиях достаточно странно требовать полного совпадения ответов модели и истинных ответов — гораздо логичнее говорить об их близости. Более того, как мы выяснили, попытка провести функцию через все обучающие точки легко может привести к переобучению. Способов посчитать близость двух чисел \(прогноза и истинного ответа\) достаточно много, и поэтому при обсуждении регрессии у нас возникло большое количество функционалов ошибки.

В случае с бинарной классификацией всё гораздо проще: у нас всего два возможных ответа алгоритма и, очевидно, мы хотим видеть как можно больше правильных ответов. Соответствующий функционал называется _долей правильных ответов_ \(accuracy\):

$$
Q(a,X) = \frac{1}{l}\sum_{i=1}^l [ a(x_i)  = y_i]
$$

Нам будет удобнее решать задачу минимизации, поэтому будем вместо этого использовать долю неправильных ответов:

$$
Q(a,X) = \frac{1}{l}\sum_{i=1}^l [ a(x_i)  \ne y_i] = 
 \frac{1}{l}\sum_{i=1}^l [ sign\langle w, x_i \rangle \ne y_i] \to \min\limits_w
$$

Этот функционал является дискретным относительно весов, и поэтому искать его минимум с помощью градиентных методов мы не сможем. Более того, у данного функционала может быть много глобальных минимумов — вполне может оказаться, что существует много способов добиться оптимального количества ошибок. Чтобы не пытаться решать все эти проблемы, попытаемся свести задачу к минимизации гладкого функционала.

### Отступы

Заметим, что функционал поиска доли неправильных ответов можно несколько видоизменить:

$$
Q(a,X) = \frac{1}{l}\sum_{i=1}^l [ \underbrace{y \langle w, x_i \rangle}_{M_i}   < 0 ]  \to \min\limits_w
$$

Здесь возникла очень важная величина $$M_i = \langle w,x_i \rangle$$, называемая _отступом_ \(margin\). Знак отступа говорит о корректности ответа классификатора \(положительный отступ соответствует правильному ответу, отрицательный — неправильному\), а его абсолютная величина характеризует степень уверенности классификатора в своём ответе. Напомним, что скалярное произведение $$\langle w, x\rangle$$ пропорционально расстоянию от разделяющей гиперплоскости до объекта; соответственно, чем ближе отступ к нулю, тем ближе объект к границе классов, тем ниже уверенность в его принадлежности.

### Метрики качества классификации

Часто возникает необходимость в изучении различных аспектов качества уже обученного классификатора. Обсудим подробнее распространённые подходы к измерению качества таких моделей. 

Будем считать, что классификатор имеет вид $$ a(x) = [b(x) > t]$$. Линейная модель имеет именно такую форму, если положить $$b(x) = \langle w, x \rangle$$ и $$t =0$$.

#### Доля правильных ответов

Наиболее очевидной мерой качества в задаче классификации является _доля правильных ответов_ \(accuracy\), которую мы уже упоминали:

$$
accuracy(a,x) = \frac{1}{l}\sum_{i=1}^l [ a(x_i)  = y_i]
$$

Данная метрика, однако, имеет существенный недостаток. Если взять порог $$t$$ меньше минимального значения прогноза $$b(x)$$ на выборке или больше максимального значения, то доля правильных ответов будет равна доле положительных и отрицательных ответов соответственно. Таким образом, если в выборке 950 отрицательных и 50 положительных объектов, то при тривиальном пороге $$t = max_i b(x_i)$$ мы получим долю правильных ответов 0.95. Это означает, что доля положительных ответов сама по себе не несет никакой информации о качестве работы алгоритма $$a(x)$$ , и вместе с ней следует анализировать соотношение классов в выборке. Также полезно вместе с долей правильных ответов вычислять _базовую долю_ — долю правильных ответов алгоритма, всегда выдающего наиболее мощный класс.

Отметим, что при сравнении различных методов машинного обучения принято сообщать относительное уменьшение ошибки. Рассмотрим два алгоритма $$a_1$$ и  $$a_2$$ с долями правильных ответов $$r_1$$ и $$r_2$$ соответственно, причем $$r_2 > r_1$$ . Относительным уменьшением ошибки алгоритма $$a_2$$ называется величина

$$
\frac{(1-r_1) - (1 - r_2 )}{1-r_1}
$$

Если доля ошибок была улучшена с 20% до 10%, то относительное улучшение составляет 50%. Если доля ошибок была улучшена с 50% до 25%, то относительное улучшение также равно 50%, хотя данный прирост кажется более существенным. Если же доля ошибок была улучшена с 0.1% до 0.01%, то относительное улучшение составляет 90%, что совершенно не соответствует здравому смыслу.

#### Матрица ошибок

Выше мы убедились, что в случае с несбалансированными классами одной доли правильных ответов недостаточно — необходима еще одна метрика качества. В данном разделе мы рассмотрим другую, более информативную пару критериев. 

Введем сначала понятие матрицы ошибок. Это способ разбить объекты на четыре категории в зависимости от комбинации истинного ответа и ответа алгоритма. Через элементы этой матрицы можно, например, выразить долю правильных ответов:

$$
accuracy = \frac{TP + TN}{TP + FP + FN + TN}
$$

Гораздо более информативными критериями являются _точность_ \(precision\) и _полнота_ \(recall\):

$$
precision = \frac{TP}{TP + FP}
$$

$$
recall = \frac{TP}{TP + FN}
$$

|  | $$y = 1$$  | $$y = -1$$  |
| :--- | :--- | :--- |
| $$a(x) = 1$$  | True Positive \(TP\) | False Positive\(FP\) |
| $$a(x) = -1$$  | False Negative \(FN\) | True Negative\(TN\)  |

Точность показывает, какая доля объектов, выделенных классификатором как положительные, действительно является положительными. Полнота показывает, какая часть положительных объектов была выделена классификатором.

Рассмотрим, например, задачу предсказания реакции клиента банка на звонок с предложением кредита. Ответ $$y =1 $$ означает, что клиент возьмет кредит после рекламного звонка, ответ $$y = −1$$ — что не возьмет. Соответственно, планируется обзванивать только тех клиентов, для которых классификатор $$ a(x) $$ вернет ответ 1. Если классификатор имеет высокую точность, то практически все клиенты, которым будет сделано предложение, откликнутся на него. Если классификатор имеет высокую полноту, то предложение будет сделано практически всем клиентам, которые готовы откликнуться на него. 

Если классификатор имеет высокую полноту, то предложение будет сделано практически всем клиентам, которые готовы откликнуться на него. Как правило, можно регулировать точность и полноту, изменяя порог $$t$$ в классификаторе $$a(x) = [b(x) > t]$$. Если выбрать $$t$$ большим, то классификатор будет относить к положительному классу небольшое число объектов, что приведет к высокой точности и низкой полноте. По мере уменьшения $$t$$ точность будет падать, а полнота увеличиваться. Конкретное значение порога выбирается согласно требованиям к алгоритму.

Отметим, что точность и полнота не зависят от соотношения размеров классов. Даже если объектов положительного класса на порядки меньше, чем объектов отрицательного класса, данные показатели будут корректно отражать качество работы алгоритма.

Существует несколько способов получить один критерий качества на основе точности и полноты. Один из них — _F-мера_, гармоническое среднее точности и полноты:

$$
F = \frac{2 \ast precision \ast recall}{precisition + recall}
$$

Среднее гармоническое обладает важным свойством — оно близко к нулю, если хотя бы один из аргументов близок к нулю. Именно поэтому оно является более предпочтительным, чем среднее арифметическое \(если алгоритм будет относить все объекты к положительному классу, то он будет иметь $$recall = 1 $$ и $$ precision \ll 1$$, а их среднее арифметическое будет больше 1/2, что недопустимо\). Можно заметить, что F-мера является сглаженной версией минимума из точности и полноты \(см. рис. 2 и 3\). Отметим, что геометрическое среднее также похоже на сглаженный вариант минимума, но при этом оно менее устойчиво к «выбросам» — например, для точности 0.9 и полноты 0.1 гармоническое среднее будет равно 0.18, а геометрическое 0.3. Другим агрегированным критерием является _R-точность_, или _точка баланса_ \(breakeven point\). Она вычисляется как точность при таком $$t$$ , при котором полнота равна точности:

$$
\text{R-precision} = precision([b(x) > t^*
]), \\
t^* = arg \min\limits_t|precision([b(x) > t]) − recall([b(x) > t])| .
$$

![&#x420;&#x438;&#x441;&#x443;&#x43D;&#x43E;&#x43A; 2,3 ](../.gitbook/assets/image%20%2856%29.png)

Можно показать, что R-точность равна точности при таком пороге, при котором количество отнесённых к положительному классу объектов равно количеству положительных объектов в выборке. 

Часто встречаются задачи, в которых целевой признак по-прежнему бинарный, но при этом необходимо ранжировать объекты, а не просто предсказывать их класс. Например, в задаче предсказания реакции клиента можно выдавать сортированный список, чтобы оператор мог в первую очередь позвонить клиентам с наибольшей вероятностью положительного отклика. Поскольку многие алгоритмы возвращают вещественный ответ $$b(x)$$ , который затем бинаризуется по порогу $$t$$ , то можно просто сортировать объекты по значению $$b(x)$$ . Для измерения качества ранжирования нередко используют _среднюю точность_ \(average precision, AP\):

$$
AP = \frac{1}{l_+} \sum_{k=1}^l [y_{(k)} = 1]precision_k
$$

где $$y_{(k)}$$ — ответ $$k$$-го по порядку объекта, $$l_+$$ — число положительных объектов в выборке, а $$precision_k$$ — точность среди первых $$k$$ в списке объектов. Если алгоритм $$b(x) $$ так ранжирует объекты, что сначала идут все положительные, а затем все отрицательные, то средняя точность будет равна единице; соответственно, чем сильнее положительные документы концентрируются в верхней части списка, тем ближе к единице будет данный показатель.

Выше мы отмечали, что высокие значения доли правильных ответов вовсе не влекут за собой высокое качество работы классификатора, и ввели точность и полноту как способ решения этой проблемы. Тем не менее, при выборе точности и полноты в качестве основных метрик, следует соблюдать осторожность при выборе требований к их значениям — как мы увидим из примера, независимость данных метрик от соотношения классов может привести к неочевидным последствиям.

Рассмотрим задачу бинарной классификации с миллионом объектов \( $$l = 1.000.000$$ \), где доля объектов первого класса составляет 1% \( $$l_+ = 10.000$$ \). Мы знаем, что доля правильных ответов будет вести себя не вполне интуитивно на данной несбалансированной выборке, и поэтому выберем точность и полноту для измерения качества классификаторов. Поскольку мы хотим решить задачу хорошо, то введём требования, что и точность, и полнота должны быть не менее 90%. Эти требования кажутся вполне разумными, если забыть о соотношении классов. Попробуем теперь оценить, какая доля правильных ответов должна быть у классификатора, удовлетворяющего нашим требованиям. Всего в выборке 10.000 положительных объектов, и для достижения полноты 90% мы должны отнести как минимум 9.000 к положительному классу. Получаем TP = 9000, FN = 1000. Так как точность тоже должна быть не меньше 90%, получаем FP = 1000. Отсюда получаем, что доля правильных ответов должна быть равна \(1 − 2.000/1.000.000\) = 99.8%! Это крайне высокий показатель, и его редко удаётся достичь на таких выборках во многих предметных областях.

#### Lift

На практике часто возникают задачи, связанные с выбором подмножества: выделение лояльных клиентов банка, обнаружение уходящих пользователей мобильного оператора и т.д. Заказчика может интересовать вопрос, насколько выгоднее работать с этим подмножеством по сравнению со всем множеством. Если при рассылке предложений о кредите клиентам из подмножества и всем клиентам будет получаться одна и та же доля откликнувшихся, то подмножество не будет представлять особой ценности. Формально это измеряется с помощью _прироста концентрации_ \(lift\), который равен отношению точности к доле положительных объектов в выборке:

$$
\text{lift} = \frac{precision}{(TP + FN)/l}
$$

Эту величину можно интерпретировать как улучшение доли положительных объектов в данном подмножестве относительно доли в случайно выбранном подмножестве такого же размера.

#### Площади под кривой

Выше мы изучили точность, полноту и F-меру, которые характеризуют качество работы алгоритма $$a(x) = [b(x) > t]$$ при конкретном выборе порога $$t$$ . Однако зачастую интерес представляет лишь вещественнозначный алгоритм $$b(x)$$ , а порог будет выбираться позже в зависимости от требований к точности и полноте. В таком случае возникает потребность в измерении качества семейства моделей $${a(x) = = [b(x) > t] |t \in \mathbb{R}}$$ .

Можно измерять качество этого множества на основе качества лучшего \(в некотором смысле\) алгоритма. Для этого подходит упомянутая ранее точка баланса \(breakeven point\). В идеальном семействе алгоритмов она будет равна единице, поскольку найдется алгоритм со стопроцентной точностью и полнотой. Данная метрика, однако, основывается лишь на качестве одного алгоритма, и не характеризует вариативность семейства. Широко используется такая интегральная метрика качества семейства, как _площадь под ROC-кривой_ \(Area Under ROC Curve, AUC-ROC\) \(рис. 3\). Рассмотрим двумерное пространство, одна из координат которого соответствует доле неверно принятых объектов \(False Positive Rate, FPR\), а другая — доле верно принятых объектов \(True Positive Rate, TPR\):

$$
FPR = \frac{FP}{FP + TN}
$$

$$
TPR = \frac{TP}{TP + FN}
$$



![&#x420;&#x438;&#x441;&#x443;&#x43D;&#x43E;&#x43A; 3 - &#x41F;&#x440;&#x438;&#x43C;&#x435;&#x440; ROC-&#x43A;&#x440;&#x438;&#x432;&#x43E;&#x439;](../.gitbook/assets/image%20%2857%29.png)

Каждый возможный выбор порога $$t$$ соответствует точке в этом пространстве. Всего различных порогов имеется $$l +1 $$ . Максимальный порог $$t_{max} = max_i b(x_i) $$ даст классификатор с TPR = 0, FPR = 0. Минимальный порог $$t_min = min_i b(x_i) − \varepsilon $$ даст TPR = 1 и FPR = 1. ROC-кривая — это кривая с концами в точках \(0, 0\) и \(1, 1\), которая последовательно соединяет точки, соответствующие порогам $$ b(x_{(1)})− \varepsilon, b(x_{(1)}), b(x_{(2)}), . . . , b(x_{(ℓ)})$$. Площадь под данной кривой называется AUC-ROC, и принимает значения от 0 до 1. Если порог $$t$$ может быть подобран так, что алгоритм $$a(x) $$ не будет допускать ошибок, то AUC-ROC будет равен единице; если же $$b(x)$$ ранжирует объекты случайным образом, то AUC-ROC будет близок к 0.5.

Критерий AUC-ROC имеет большое число интерпретаций — например, он равен вероятности того, что случайно выбранный положительный объект окажется позже случайно выбранного отрицательного объекта в ранжированном списке, порожденном $$b(x)$$.

#### Индекс Джини

В задачах кредитного скоринга вместо AUC-ROC часто используется пропорциональная метрика, называемая индексом Джини \(Gini index\):

$$
Gini = 2AUC -1
$$

По сути это площадь между ROC-кривой и диагональю соединяющей точки \(0, 0\) и \(1, 1\). Отметим, что переход от AUC к индексу Джини приводит к увеличению относительных разниц. 

Если мы смогли улучшить AUC с 0.8 до 0.9, то это соответствует относительному улучшению в 12.5%. В то же время соответствующие индексы Джини были улучшены с 0.6 до 0.8, то есть на 33.3% — относительное улучшение повысилось почти в три раза!

Рассмотрим задачу выделения математических статей из множества научных статей. Допустим, что всего имеется 1.000.100 статей, из которых лишь 100 относятся к математике. Если нам удастся построить алгоритм $$a(x)$$ , идеально решающий задачу, то его TPR будет равен единице, а FPR — нулю. Рассмотрим теперь плохой алгоритм, дающий положительный ответ на 95 математических и 50.000 нематематических статьях. Такой алгоритм совершенно бесполезен, но при этом имеет TPR = 0.95 и FPR = 0.05, что крайне близко к показателям идеального алгоритма. 

Таким образом, если положительный класс существенно меньше по размеру, то AUC-ROC может давать неадекватную оценку качества работы алгоритма, поскольку измеряет долю неверно принятых объектов относительно общего числа отрицательных. Так, алгоритм $$b(x)$$ , помещающий 100 релевантных документов на позиции с 50.001-й по 50.101-ю, будет иметь AUC-ROC 0.95.

Избавиться от указанной проблемы с несбалансированными классами можно, перейдя от ROC-кривой к _Precision-Recall кривой_. Она определяется аналогично ROC-кривой, только по осям откладываются не FPR и TPR, а полнота \(по оси абсцисс\) и точность \(по оси ординат\). Критерием качества семейства алгоритмов выступает площадь под PR-кривой \(AUC-PR\). Данную величину можно аппроксимировать следующим образом. Стартуем из точки \(0, 1\). Будем идти по ранжированной выборке, начиная с первого объекта; пусть текущий объект находится на позиции $$k$$ . Если он относится к классу «−1», то полнота не меняется, точность падает — соответственно, кривая опускается строго вниз. Если же объект относится к классу «1», то полнота увеличивается на $$1/ l_+$$ , точность растет, и кривая поднимается вправо и вверх. Площадь под этим участком можно аппроксимировать площадью прямоугольника с высотой, равной $$precision_k$$ и шириной $$1/l_+$$ . При таком способе подсчета площадь под PR-кривой будет совпадать со средней точностью:

$$
\text{AUC-PR} = \frac{1}{l_+} \sum_{i=1}^l [y_i = 1]precision_k
$$

Отметим, что AUC-PR дает разумные результаты в рассмотренном выше примере с классификацией статей. Так, при размещении 100 релевантных документов на позициях 50.001-50.101 в ранжированном списке, AUC-PR будет равен 0.001. Несмотря на указанные различия, между ROC- и PR-кривой имеется тесная связь. Так, можно показать, что если ROC-кривая одного алгоритма лежит полностью над ROC-кривой другого алгоритма, то и PR-кривая одного лежит над PRкривой другого.

### Логистическая регрессия 

Метод обучения, которые получается при использовании логистической функции потерь, называется логистической регрессией. Основным его свойством является тот факт, что он корректно оценивает вероятность принадлежности объекта к каждому из классов.

Пусть в каждой точке пространства объектов $$x \in \mathbb{X}$$ задана вероятность $$p(y = +1 |x)$$ того, что объект $$x$$ будет принадлежать классу $$+1$$ . Это означает, что мы допускаем наличие в выборке нескольких объектов с одинаковым признаковым описанием, но с разными значениями целевой переменной; причём если устремить количество объекта x в выборке к бесконечности, то доля положительных объектов среди них будет стремиться к $$p(y = +1 | x)$$.

Примером может служить задача предсказания кликов по рекламным баннерам. При посещении одного и того же сайта один и тот же пользователь может как кликнуть, так и не кликнуть по одному и тому же баннеру, из-за чего в выборке могут появиться одинаковые объекты с разными ответами. При этом важно, чтобы классификатор предсказывал именно вероятности классов — если домножить вероятность первого класса на сумму, которую заплатит заказчик в случае клика, то мы получим матожидание прибыли при показе этого баннера. На основе таких матожиданий можно построить алгоритм, выбирающий баннеры для показа пользователю.

Итак, рассмотрим точку x пространства объектов. Как мы договорились, в ней имеется распределение на ответах $$p(y = +1 | x)$$ . Допустим, алгоритм $$b(x)$$ возвращает числа из отрезка $$[0, 1]$$. Наша задача — выбрать для него такую процедуру обучения, что в точке $$x$$ ему будет оптимально выдавать число $$p(y = +1 | x)$$. Если в выборке объект $$x$$ встречается $$n$$ раз с ответами $$\{ y_1, . . . , y_n\}$$ , то получаем следующее требование:

$$
arg \min\limits_{b \in \mathbb{R}} \frac{1}{n} \sum_{i=1}^n L(y_i, b) \approx p(y = +1|x)
$$

При стремлении n к бесконечности получим, что функционал стремится к матожиданию ошибки:

$$
arg \min\limits_{b \in \mathbb{R}} \mathbb{E} [L(y,b) | x] = p(y = +1 | x)
$$

Хотя квадратичная функция потерь и приводит к корректному оцениванию вероятностей, она не очень хорошо подходит для решения задачи классификации. Причиной этому в том числе являются и слишком низкие штрафы за ошибку — так, если объект положительный, а модель выдаёт для него вероятность первого класса $$b(x) = 0$$ , то штраф за это равен всего лишь единице: $$(1 − 0)^2 = 1$$ .

Попробуем сконструировать функцию потерь из других соображений. Если алгоритм $$b(x) \in [0, 1]$$ действительно выдает вероятности, то они должны согласовываться с выборкой. С точки зрения алгоритма вероятность того, что в выборке встретится объект $$x_i$$ с классом $$y_i$$ , равна $$b(x_i)^{[y_i =+1]}(1 - b(x_i))^{[y_i = -1]}$$. Исходя из этого, можно записать правдоподобие выборки \(т.е. вероятность получить такую выборку с точки зрения алгоритма\):

$$
(a, X) = \prod_{i=1}^l b(x_i)^{[y_i = +1]} (1 - b(x_i))^{[y_i= -1]}
$$

Данное правдоподобие можно использовать как функционал для обучения алгоритма — с той лишь оговоркой, что удобнее оптимизировать его логарифм:

$$
- \sum_{i=1}^l ([y_i = +1])\log b(x_i) + [y =-1]\log (1-b(x_i)) \to \min
$$

Данная функция потерь называется логарифмической \(log-loss\). Покажем, что она также позволяет корректно предсказывать вероятности. Запишем матожидание функции потерь в точке $$x$$:

$$
\mathbb{E} \left[ 
L (y,b)|x 
\right] = \mathbb{E} \left[ 
-[y=+1]\log b - [y = -1] \log(1-b)|x 
\right] \\ = -p(y=+1|x)\log b - (1- p(y = +1 |x))\log(1-b)
$$

Продифференцируем по $$b$$:

$$
\frac{\partial }{\partial b} \mathbb{E} \left[ 
L(y,b)|x
\right] = - \frac{p(y =+1|x)}{b} + \frac{1 - p(y = -1|x)}{1-b} = 0
$$

Оптимальный ответ алгоритма равен вероятности положительного класса:

$$
b_* = p(y = +1|x)
$$

Везде выше мы требовали, чтобы алгоритм $$b(x)$$ возвращал числа из отрезка $$[0, 1]$$ . Этого легко достичь, если положить $$b(x) = \sigma(\langle w, x \rangle)$$ , где в качестве $$\sigma$$ может выступать любая монотонно неубывающая функция с областью значений $$[0, 1]$$. Мы будем использовать сигмоидную функцию: $$\sigma(z) = \frac{1}{1+ \exp(-z)}$$ . Таким образом, чем больше скалярное произведение $$\langle w, x \rangle$$ , тем больше будет предсказанная вероятность. Как при этом можно интерпретировать данное скалярное произведение? Чтобы ответить на этот вопрос, преобразуем уравнение

$$
p(y =1|x) = \frac{1}{1+ \exp(- \langle w,x \rangle)}
$$

Выражая из него скалярное произведение, получим

$$
\langle w,x \rangle = \log \frac{p(y=+1|x)}{p(y = -1|x)}
$$

Получим, что скалярное произведение будет равно логарифму отношения вероятностей классов \(log-odds\). 

Как уже упоминалось выше, при использовании квадратичной функции потерь алгоритм будет пытаться предсказывать вероятности, но данная функция потерь является далеко не самой лучшей, поскольку слабо штрафует за грубые ошибки. 

Логарифмическая функция потерь подходит гораздо лучше, поскольку не позволяет алгоритму сильно ошибаться в вероятностях. Подставим трансформированный ответ линейной модели в логарифмическую функцию потерь:

$$
-\sum_{i=1}^l \big( 
[y_i = +1] \log \frac{1}{1+ \exp(-\langle w, x_i \rangle)} + [y_i = -1]\log \frac{exp(- \langle w, x_i \rangle)}{1 + \exp(- \langle w,x_i \rangle)}
\big) \\
= \sum_{i=1}^l \log(1+ \exp(- y_i \langle w,x_i \rangle))
$$

Полученная функция в точности представляет собой логистические потери, упомянутые в начале. Линейная модель классификации, настроенная путём минимизации данного функционала, называется логистической регрессией. Как видно из приведенных рассуждений, она оптимизирует правдоподобие выборки и дает корректные оценки вероятности принадлежности к положительному классу.

### Метод опорных векторов

Рассмотрим теперь другой подход к построению функции потерь, основанный на максимизации зазора между классами. Будем рассматривать линейные классификаторы вида

$$
a(x) = sign(\langle w,x \rangle + b), w \in \mathbb{R}^d, b \in \mathbb{R}
$$

Будем считать, что существуют такие параметры $$w_*$$ и $$b_*$$ , что соответствующий им классификатор $$a(x)$$ не допускает ни одной ошибки на обучающей выборке. В этом случае говорят, что выборка _линейно разделима_.

Можно показать, что расстояние от произвольной точки $$x_0 \in \mathbb{R}^d$$ до гиперплоскости, определяемой данным классификатором, равно

$$
\rho (x_0, a) = \frac{| \langle w, x \rangle + b|}{\| w\|}
$$

Тогда расстояние от гиперплоскости до ближайшего объекта обучающей выборки равно

$$
\min\limits_{x \in X^l} \frac{| \langle w, x \rangle +b|}{\| w\|} = \frac{1}{\| w\|}\min\limits_{x \in X} |\langle w,x \rangle + b| = \frac{1}{\|w\|}
$$

Данная величина также называется _отступом_ \(margin\).

Таким образом, если классификатор без ошибок разделяет обучающую выборку, то ширина его разделяющей полосы равна $$\frac{2}{\|w\|}$$ . Известно, что максимизация ширины разделяющей полосы приводит к повышению обобщающей способности классификатора. Вспомним также, что на повышение обобщающей способности направлена и регуляризация, которая штрафует большую норму весов — а чем больше норма весов, тем меньше ширина разделяющей полосы. Итак, требуется построить классификатор, идеально разделяющий обучающую выборку, и при этом имеющий максимальный отступ. Запишем соответствующую оптимизационную задачу, которая и будет определять метод опорных векторов для линейно разделимой выборки \(hard margin support vector machine\):

$$
\begin{cases} 
\frac{1}{2}\|w\|^2 \to \min\limits_{w,b} \\
y_i(\langle w,x_i \rangle + b) \ge 1 , i= 1, ..., l
\end{cases}
$$

Здесь мы воспользовались тем, что линейный классификатор дает правильный ответ на объекте $$x_i$$ тогда и только тогда, когда $$ y_i(\langle w, x_i \rangle + b) \ge 0$$ . Более того, из условия нормировки следует, что $$y_i(\langle w, x_i \rangle + b) \ge 1$$.

### Логистическая регрессия в Scilab

Рассмотрим пример написания логистической регрессии в среде Sciab. 

Сгенерируем случайное распределение двух классовых меток зависящих от $$x$$ и $$y$$и выведем  график распределения:

```text
b0 = 10;
t = b0 * rand(100,2);
t = [t 0.5+0.5*sign(t(:,2)+t(:,1)-b0)];

b = 1;
flip = find(abs(t(:,2)+t(:,1)-b0)<b);
t(flip,$)=grand(length(t(flip,$)),1,"uin",0,1);
t0 = t(find(t(:,$)==0),:);
t1 = t(find(t(:,$)==1),:);

plot(t0(:,1),t0(:,2),'bo')
plot(t1(:,1),t1(:,2),'rx')
```

На строках 1-3 происходит заполнение массива случайными числами по закону распределения рассмотренному ранее. 

В строках 5-9 происходит случайное перемешивание данных и распределение по классовой принадлежности. 

В строках 11, 12 происходит построение графика распределения точек \(рис. 4\)

![&#x420;&#x438;&#x441;&#x443;&#x43D;&#x43E;&#x43A; 4 - &#x41F;&#x440;&#x438;&#x43C;&#x435;&#x440; &#x433;&#x440;&#x430;&#x444;&#x438;&#x43A;&#x430; &#x440;&#x430;&#x441;&#x43F;&#x440;&#x435;&#x434;&#x435;&#x43B;&#x435;&#x43D;&#x438;&#x44F; &#x442;&#x43E;&#x447;&#x435;&#x43A; &#x441; &#x43A;&#x43B;&#x430;&#x441;&#x441;&#x43E;&#x432;&#x44B;&#x43C;&#x438; &#x43C;&#x435;&#x442;&#x43A;&#x430;&#x43C;&#x438;](../.gitbook/assets/image%20%2859%29.png)

Теперь опишем алгоритм логистической регрессии для поиска разделяющей гиперплоскости для данного набора данных.

```text
x = t(:, 1:$-1); y = t(:, $);
[m, n] = size(x);
x = [ones(m, 1) x];
w = zeros(n + 1, 1);
a = 0.01;
n_iter = 10000;
for iter = 1:n_iter do
    z = x * w;
    sigmoid = ones(z) ./ (1+exp(-z));
    w = w - a * x' *(sigmoid-y) / m;
    E(iter) = (-y' * log(sigmoid) - (1-y)' * log(1-sigmoid))/m;
end
```

В строках 1-3 происходит разделение данных на вектор признаков и$$1,x$$ и выходные значения $$y$$. В строке 3 определяем вектор весов $$w$$, которые будем оптимизировать.  

Начиная со строки 7 начинает цикл длиной в `n_iter` в котором происходит поиск оптимальных параметров $$w$$.

В строке 8 находим произведение вес-признак $$\langle w, x \rangle$$. В строке 9 находим значение фунции-сигмоиды для вычисления достоверности алгоритма.

В строке 10 происходит оптимизация значений $$w$$.

В строке 11 находим значение функции потери: $$\frac{-p(y=+1|x)\log b - (1- p(y = +1 |x))\log(1-b)}{l}$$ 

После поиска оптимального значения можно приступать к визуализации полученных результатов. Построим график распределения данных вместе с разделяющей плоскостью, коэфициенты которой искал алгоритм логистической регрессии.

```text
u = linspace(min(x(:,2)),max(x(:,2))); \\ оси для графика 
clf(1);scf(1);
plot(t0(:,1),t0(:,2),'bo')
plot(t1(:,1),t1(:,2),'rx')
plot(u,-(w(1)+w(2)*u)/w(3),'-g')
```

###  Машина опорных векторов в Scilab

Для работы с алгоритмом SVM необходимо установить модуль **libsvm.** Для этого можно воспользоваться пакетным меню Scilab.

**Установка libsvm**

1. Выберите иконку пакетного менеджера ATOMS в меню среды Scilab ![](../.gitbook/assets/image%20%2858%29.png) 
2. В открывшемся окне пакетного менеджера выберите категорию: **Data Analisys** -&gt; **Statistics - Statistics**
3. В открывшемся меню выберите пакет **libsvm and liblinear**
4. Нажмите кнопку **Установить**
5. Перезапустите среду Scilab

**Работа с машиной опорных векторов**

Для примера снова проведем генерацию случайного множества точек и их классов. 

```text
b0 = 10;
t = b0 * rand(100,2);
t = [t 0.5+0.5*sign(t(:,2)+t(:,1)-b0)];

b = 1;
flip = find(abs(t(:,2)+t(:,1)-b0)<b);
t(flip,$)=grand(length(t(flip,$)),1,"uin",0,1);
t0 = t(find(t(:,$)==0),:);
t1 = t(find(t(:,$)==1),:);

plot(t0(:,1),t0(:,2),'bo')
plot(t1(:,1),t1(:,2),'rx')
```

Разделим множество точек на признаки и метки объектов:

```text
x = t(:, 1:$-1); y = t(:, $);
```

Поскольку классификация достаточно проста, в библиотеке libsvm существует специальный метод, позволяющий сразу визуализировать результат классиикации при помощи машины опорных векторов. 

```text
libsvm_toy(y, x)
```

В результате сразу происходит построение графика данных с разделяющей плоскостью. 

## Ход работы 

### Задание 1. Логистическая регрессия \(простая\)

Постройте модель логистической регрессии для сгенерированного множества данных. Измените параметры генерации множества данных и параметр $$a$$ 

### Задание 2. Сравнение libsvm и простой логистической регрессии

Выделите некоторую часть данных из сгенерированного множества, это будет тестовая выборка.

Прочтите справку по функции  `libsvm_svmtrain` и  `libsvm_svmpredict`

Обучите модель на данных и сделайте предсказания для тестовой выборки. 

## Контрольные вопросы

1. Дайте характеристику механизму работы линейного классификатора
2. Дайте определения понятиям: точность, полнота, F-мера

### **Критерии оценки практического занятия**

Оценивается знание материала, способность к его обобщению, критическому осмыслению, систематизации. 

* 3 балла: студент полностью выполнил задания.
* 2 балла: в усвоении учебного материала допущены небольшие пробелы.
* 1 балл: неполно или непоследовательно реализовано задание.
* 0 баллов: не раскрыто основное содержание учебного материала.

**Максимальный балл: 3 балла**

